{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\huynn5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings data\n",
    "ratings = tfds.load('movielens/100k-ratings', split='train')\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load('movielens/100k-movies', split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7], dtype=int64),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4], dtype=int64),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out unique user ids and movie titles present in the data\n",
    "# Map the raw values of our categorical features to embedding vectors in our model\n",
    "# Need a vocabulary that maps a raw feature value to an integer in a continguous range:\n",
    "# Allow us to look up the corresponding embeddings in our embedding tables\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x['user_id'])\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'10', b'100', b'101', b'102', b'103', b'104', b'105',\n",
       "       b'106', b'107'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
       "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
       "       b'2 Days in the Valley (1996)',\n",
       "       b'20,000 Leagues Under the Sea (1954)',\n",
       "       b'2001: A Space Odyssey (1968)',\n",
       "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       "       b'39 Steps, The (1935)'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a model\n",
    "\n",
    "- Choosing the architecture of our model is a key part of modelling\n",
    "- Build each tower separately and then combine them in the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The query tower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Decide on the dimensionality of the query and candidate representations\n",
    "    - Higher values - More accurate, slower to fit and more prone to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the model itself\n",
    "    - Use Keras preprocessing layers\n",
    "        - Convert user ids to integers\n",
    "        - Convert those to user embeddings via an Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\huynn5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\huynn5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary = unique_user_ids, mask_token = None),\n",
    "    # We add an additonal embedding to account for unknown tokens\n",
    "    tf.keras.layers.Embedding(\n",
    "        len(unique_user_ids) + 1, embedding_dimension\n",
    "    )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The candidate tower\n",
    "\n",
    "- Same process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary = unique_movie_titles, mask_token = None\n",
    "    ),\n",
    "    tf.keras.layers.Embedding(\n",
    "        len(unique_movie_titles) + 1, embedding_dimension\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- Positive (user, movie) pairs\n",
    "\n",
    "- Compare the affinity score:\n",
    "    - The model calculates for this pair\n",
    "    - The scores of all the other possible candidates\n",
    "        - Score for the positive pair is higher than for all other candidates\n",
    "        - Model is highly accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computes metrics for across top K candidates surfaced by a retrieval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([-0.01209145, -0.0066663 , -0.02720197, -0.01383629, -0.03274977,\n",
       "       -0.01382963, -0.00368534,  0.03022784, -0.00018349, -0.00999007,\n",
       "       -0.03370863,  0.00989441,  0.03782536, -0.03334512,  0.04180057,\n",
       "       -0.03700452,  0.01867371, -0.02007198, -0.02820513, -0.03657375,\n",
       "       -0.02700253, -0.03120247, -0.00160524, -0.04318767, -0.03019379,\n",
       "       -0.02626796, -0.00512732, -0.03145923, -0.04999689,  0.00602558,\n",
       "       -0.02734362, -0.00580493], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in movies.batch(128).map(movie_model)][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\huynn5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\huynn5\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates = movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "- TFRS has several loss layers and tasks to make this easy\n",
    "- Use Retrieval task object:\n",
    "    - A convenience wrapper\n",
    "    - Bundles together the loss function and metric computation\n",
    "\n",
    "- Task itself is a Keras layer\n",
    "    - Takes the query and candidate embeddings as arguments\n",
    "    - Returns the computed loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics = metrics\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "    def __init__(self, user_model, movie_model):\n",
    "        super().__init__()\n",
    "        self.movie_model: tf.keras.Model = movie_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training = False) -> tf.Tensor:\n",
    "        # Pick out user features and pass them into the user model\n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        # Pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back\n",
    "        positive_movie_embeddings = self.movie_model(features['movie_title'])\n",
    "        # Task computes the loss and the metrics\n",
    "        return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tfrs.Model base class\n",
    "    - Convenience class\n",
    "    - Compute both training and test losses using the same method\n",
    "(Still a plain Keras model, achieve the same functionality by inheriting from tf.keras.Model\n",
    "and overriding the train_step and test_step functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantitate the model\n",
    "model = MovielensModel(user_model, movie_model)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 6s 488ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0089 - factorized_top_k/top_10_categorical_accuracy: 0.0192 - factorized_top_k/top_50_categorical_accuracy: 0.0951 - factorized_top_k/top_100_categorical_accuracy: 0.1721 - loss: 69833.0426 - regularization_loss: 0.0000e+00 - total_loss: 69833.0426\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 5s 475ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0024 - factorized_top_k/top_5_categorical_accuracy: 0.0184 - factorized_top_k/top_10_categorical_accuracy: 0.0369 - factorized_top_k/top_50_categorical_accuracy: 0.1652 - factorized_top_k/top_100_categorical_accuracy: 0.2894 - loss: 67505.5348 - regularization_loss: 0.0000e+00 - total_loss: 67505.5348\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 5s 492ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.0216 - factorized_top_k/top_10_categorical_accuracy: 0.0435 - factorized_top_k/top_50_categorical_accuracy: 0.1845 - factorized_top_k/top_100_categorical_accuracy: 0.3123 - loss: 66326.9595 - regularization_loss: 0.0000e+00 - total_loss: 66326.9595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1552f7ec340>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 160ms/step - factorized_top_k/top_1_categorical_accuracy: 7.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0084 - factorized_top_k/top_10_categorical_accuracy: 0.0209 - factorized_top_k/top_50_categorical_accuracy: 0.1226 - factorized_top_k/top_100_categorical_accuracy: 0.2340 - loss: 31085.3350 - regularization_loss: 0.0000e+00 - total_loss: 31085.3350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.000699999975040555,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.008449999615550041,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.020899999886751175,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.12264999747276306,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.23399999737739563,\n",
       " 'loss': 28248.1484375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28248.1484375}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance is worse than training performance\n",
    "    - Perform better on the data that is has seen \n",
    "    (Overfitting is strong when models have many parameters)\n",
    "    (Can be mediated by model regularization and use of user and movie features that help the model generalize better to unseen data)\n",
    "    - The model is re-recommending some of users' already watched movies\n",
    "    (Known-positive watches can crowd out test movies out of top K recommendations)\n",
    "    (Tackled by excluding previously seen movies from test recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b\"Kid in King Arthur's Court, A (1995)\"\n",
      " b'Homeward Bound: The Incredible Journey (1993)' b'101 Dalmatians (1996)']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "    tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "# Get recommendations\n",
    "_, titles = index(tf.constant(['42']))\n",
    "print(f'Recommendations for user 42: {titles[0, :3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model serving\n",
    "\n",
    "- Serving has 2 components:\n",
    "    - A serving query model, taking in features of the query and transforming them into a \n",
    "    query embedding, and\n",
    "    - A serving candidate model.\n",
    "        - Takes the form of an approximate nearest neighbours (ANN) index\n",
    "        - Allows fast approximate lookup of candidates in response to a query produced\n",
    "        by the query model\n",
    "\n",
    "- Both components can be packaged into a single exportable model\n",
    "    - Takes the raw user id\n",
    "    - Returns the titles of top movies for that user\n",
    "        - Done via exporting the model to a SavedModel format\n",
    "        - Makes it possible to serve using TensorFlow Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\huynn5\\AppData\\Local\\Temp\\tmpqnxxxdg9\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\huynn5\\AppData\\Local\\Temp\\tmpqnxxxdg9\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b\"Kid in King Arthur's Court, A (1995)\"\n",
      " b'Homeward Bound: The Incredible Journey (1993)' b'101 Dalmatians (1996)']\n"
     ]
    }
   ],
   "source": [
    "# Export BruteForce layer\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, 'model')\n",
    "\n",
    "    # Save the index.\n",
    "    tf.saved_model.save(index, path)\n",
    "\n",
    "    # Load it back; can also be done in TensorFlow Serving.\n",
    "    loaded = tf.saved_model.load(path)\n",
    "\n",
    "    # Pass a user id in, get top predicted movie titles back.\n",
    "    scores, titles = loaded(['42'])\n",
    "\n",
    "    print(f'Recommendations: {titles[0][:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Export an approximate retrieval index to speed up predictions\n",
    "    - Possible to efficiently surface recommendations from sets of tens of millions of candidates\n",
    "- Use the scann package\n",
    "    - Optional dependency of TFRS and we installed it separately at the beginning of this tutorial by calling !pip install -q scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model)\n",
    "# scann_index.index_from_dataset(\n",
    "#     tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    "# )\n",
    "# # Get recommendations.\n",
    "# _, titles = scann_index(tf.constant([\"42\"]))\n",
    "# print(f\"Recommendations for user 42: {titles[0, :3]}\")\n",
    "# # Export the query model.\n",
    "# with tempfile.TemporaryDirectory() as tmp:\n",
    "#   path = os.path.join(tmp, \"model\")\n",
    "\n",
    "#   # Save the index.\n",
    "#   tf.saved_model.save(\n",
    "#       scann_index,\n",
    "#       path,\n",
    "#       options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
    "#   )\n",
    "\n",
    "#   # Load it back; can also be done in TensorFlow Serving.\n",
    "#   loaded = tf.saved_model.load(path)\n",
    "\n",
    "#   # Pass a user id in, get top predicted movie titles back.\n",
    "#   scores, titles = loaded([\"42\"])\n",
    "\n",
    "#   print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Item-to-Item recommendation\n",
    "    - Created user-movie model\n",
    "    - Commong to perform item-to-item recommendations\n",
    "    - Same pattern but different training data\n",
    "    - Have 2 item towers (for the query and candidate item), Train the model using (query item, candidate item) pairs\n",
    "        - Constructed from clicks on product detail pages\n",
    "\n",
    "- Next steps\n",
    "    - Learning multi-task models: jointly optimizing for ratings and clicks\n",
    "    - Using movie metadata: build a more complex movie model to alleviate cold-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
